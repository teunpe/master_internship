{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import argparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "MLP(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        logits = self.fc3(x)\n",
    "        return logits\n",
    "\n",
    "model = MLP().to(device)\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "mnist_train = datasets.MNIST('./mnist', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST('./mnist', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=mnist_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device=device, train_loader=train_loader, optimizer=optimizer, epochs=14, log_interval=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device=device, test_loader=test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn.functional.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.324760\n",
      "Train Epoch: 0 [320/60000 (1%)]\tLoss: 2.307435\n",
      "Train Epoch: 0 [640/60000 (1%)]\tLoss: 2.300279\n",
      "Train Epoch: 0 [960/60000 (2%)]\tLoss: 2.329796\n",
      "Train Epoch: 0 [1280/60000 (2%)]\tLoss: 2.363742\n",
      "Train Epoch: 0 [1600/60000 (3%)]\tLoss: 2.322748\n",
      "Train Epoch: 0 [1920/60000 (3%)]\tLoss: 2.335589\n",
      "Train Epoch: 0 [2240/60000 (4%)]\tLoss: 2.320942\n",
      "Train Epoch: 0 [2560/60000 (4%)]\tLoss: 2.304904\n",
      "Train Epoch: 0 [2880/60000 (5%)]\tLoss: 2.307624\n",
      "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 2.298847\n",
      "Train Epoch: 0 [3520/60000 (6%)]\tLoss: 2.327993\n",
      "Train Epoch: 0 [3840/60000 (6%)]\tLoss: 2.320943\n",
      "Train Epoch: 0 [4160/60000 (7%)]\tLoss: 2.319995\n",
      "Train Epoch: 0 [4480/60000 (7%)]\tLoss: 2.328945\n",
      "Train Epoch: 0 [4800/60000 (8%)]\tLoss: 2.327298\n",
      "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 2.335023\n",
      "Train Epoch: 0 [5440/60000 (9%)]\tLoss: 2.278872\n",
      "Train Epoch: 0 [5760/60000 (10%)]\tLoss: 2.337774\n",
      "Train Epoch: 0 [6080/60000 (10%)]\tLoss: 2.309146\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.308407\n",
      "Train Epoch: 0 [6720/60000 (11%)]\tLoss: 2.324088\n",
      "Train Epoch: 0 [7040/60000 (12%)]\tLoss: 2.303815\n",
      "Train Epoch: 0 [7360/60000 (12%)]\tLoss: 2.322677\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 2.311137\n",
      "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 2.323240\n",
      "Train Epoch: 0 [8320/60000 (14%)]\tLoss: 2.324074\n",
      "Train Epoch: 0 [8640/60000 (14%)]\tLoss: 2.292884\n",
      "Train Epoch: 0 [8960/60000 (15%)]\tLoss: 2.327362\n",
      "Train Epoch: 0 [9280/60000 (15%)]\tLoss: 2.301817\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 2.284823\n",
      "Train Epoch: 0 [9920/60000 (17%)]\tLoss: 2.317000\n",
      "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 2.314831\n",
      "Train Epoch: 0 [10560/60000 (18%)]\tLoss: 2.318923\n",
      "Train Epoch: 0 [10880/60000 (18%)]\tLoss: 2.347989\n",
      "Train Epoch: 0 [11200/60000 (19%)]\tLoss: 2.289340\n",
      "Train Epoch: 0 [11520/60000 (19%)]\tLoss: 2.301334\n",
      "Train Epoch: 0 [11840/60000 (20%)]\tLoss: 2.312069\n",
      "Train Epoch: 0 [12160/60000 (20%)]\tLoss: 2.291112\n",
      "Train Epoch: 0 [12480/60000 (21%)]\tLoss: 2.336140\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.306338\n",
      "Train Epoch: 0 [13120/60000 (22%)]\tLoss: 2.317784\n",
      "Train Epoch: 0 [13440/60000 (22%)]\tLoss: 2.309771\n",
      "Train Epoch: 0 [13760/60000 (23%)]\tLoss: 2.323200\n",
      "Train Epoch: 0 [14080/60000 (23%)]\tLoss: 2.317690\n",
      "Train Epoch: 0 [14400/60000 (24%)]\tLoss: 2.330482\n",
      "Train Epoch: 0 [14720/60000 (25%)]\tLoss: 2.348871\n",
      "Train Epoch: 0 [15040/60000 (25%)]\tLoss: 2.307638\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 2.278823\n",
      "Train Epoch: 0 [15680/60000 (26%)]\tLoss: 2.296710\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 2.337130\n",
      "Train Epoch: 0 [16320/60000 (27%)]\tLoss: 2.343207\n",
      "Train Epoch: 0 [16640/60000 (28%)]\tLoss: 2.314153\n",
      "Train Epoch: 0 [16960/60000 (28%)]\tLoss: 2.309374\n",
      "Train Epoch: 0 [17280/60000 (29%)]\tLoss: 2.333876\n",
      "Train Epoch: 0 [17600/60000 (29%)]\tLoss: 2.314814\n",
      "Train Epoch: 0 [17920/60000 (30%)]\tLoss: 2.335212\n",
      "Train Epoch: 0 [18240/60000 (30%)]\tLoss: 2.275371\n",
      "Train Epoch: 0 [18560/60000 (31%)]\tLoss: 2.324845\n",
      "Train Epoch: 0 [18880/60000 (31%)]\tLoss: 2.308733\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.289245\n",
      "Train Epoch: 0 [19520/60000 (33%)]\tLoss: 2.303048\n",
      "Train Epoch: 0 [19840/60000 (33%)]\tLoss: 2.326689\n",
      "Train Epoch: 0 [20160/60000 (34%)]\tLoss: 2.296074\n",
      "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 2.323193\n",
      "Train Epoch: 0 [20800/60000 (35%)]\tLoss: 2.308456\n",
      "Train Epoch: 0 [21120/60000 (35%)]\tLoss: 2.309477\n",
      "Train Epoch: 0 [21440/60000 (36%)]\tLoss: 2.321993\n",
      "Train Epoch: 0 [21760/60000 (36%)]\tLoss: 2.303084\n",
      "Train Epoch: 0 [22080/60000 (37%)]\tLoss: 2.316317\n",
      "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 2.293450\n",
      "Train Epoch: 0 [22720/60000 (38%)]\tLoss: 2.321608\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 2.275454\n",
      "Train Epoch: 0 [23360/60000 (39%)]\tLoss: 2.312670\n",
      "Train Epoch: 0 [23680/60000 (39%)]\tLoss: 2.275567\n",
      "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 2.335333\n",
      "Train Epoch: 0 [24320/60000 (41%)]\tLoss: 2.314065\n",
      "Train Epoch: 0 [24640/60000 (41%)]\tLoss: 2.321101\n",
      "Train Epoch: 0 [24960/60000 (42%)]\tLoss: 2.296949\n",
      "Train Epoch: 0 [25280/60000 (42%)]\tLoss: 2.299771\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.306051\n",
      "Train Epoch: 0 [25920/60000 (43%)]\tLoss: 2.273075\n",
      "Train Epoch: 0 [26240/60000 (44%)]\tLoss: 2.315719\n",
      "Train Epoch: 0 [26560/60000 (44%)]\tLoss: 2.311035\n",
      "Train Epoch: 0 [26880/60000 (45%)]\tLoss: 2.325615\n",
      "Train Epoch: 0 [27200/60000 (45%)]\tLoss: 2.325603\n",
      "Train Epoch: 0 [27520/60000 (46%)]\tLoss: 2.316053\n",
      "Train Epoch: 0 [27840/60000 (46%)]\tLoss: 2.298029\n",
      "Train Epoch: 0 [28160/60000 (47%)]\tLoss: 2.296840\n",
      "Train Epoch: 0 [28480/60000 (47%)]\tLoss: 2.301892\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 2.336228\n",
      "Train Epoch: 0 [29120/60000 (49%)]\tLoss: 2.290975\n",
      "Train Epoch: 0 [29440/60000 (49%)]\tLoss: 2.313807\n",
      "Train Epoch: 0 [29760/60000 (50%)]\tLoss: 2.334484\n",
      "Train Epoch: 0 [30080/60000 (50%)]\tLoss: 2.321251\n",
      "Train Epoch: 0 [30400/60000 (51%)]\tLoss: 2.327246\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 2.313441\n",
      "Train Epoch: 0 [31040/60000 (52%)]\tLoss: 2.283297\n",
      "Train Epoch: 0 [31360/60000 (52%)]\tLoss: 2.318263\n",
      "Train Epoch: 0 [31680/60000 (53%)]\tLoss: 2.283564\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 2.333395\n",
      "Train Epoch: 0 [32320/60000 (54%)]\tLoss: 2.317356\n",
      "Train Epoch: 0 [32640/60000 (54%)]\tLoss: 2.352597\n",
      "Train Epoch: 0 [32960/60000 (55%)]\tLoss: 2.304489\n",
      "Train Epoch: 0 [33280/60000 (55%)]\tLoss: 2.318453\n",
      "Train Epoch: 0 [33600/60000 (56%)]\tLoss: 2.306099\n",
      "Train Epoch: 0 [33920/60000 (57%)]\tLoss: 2.349821\n",
      "Train Epoch: 0 [34240/60000 (57%)]\tLoss: 2.348441\n",
      "Train Epoch: 0 [34560/60000 (58%)]\tLoss: 2.309293\n",
      "Train Epoch: 0 [34880/60000 (58%)]\tLoss: 2.296534\n",
      "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 2.291230\n",
      "Train Epoch: 0 [35520/60000 (59%)]\tLoss: 2.303281\n",
      "Train Epoch: 0 [35840/60000 (60%)]\tLoss: 2.288763\n",
      "Train Epoch: 0 [36160/60000 (60%)]\tLoss: 2.308604\n",
      "Train Epoch: 0 [36480/60000 (61%)]\tLoss: 2.294164\n",
      "Train Epoch: 0 [36800/60000 (61%)]\tLoss: 2.325400\n",
      "Train Epoch: 0 [37120/60000 (62%)]\tLoss: 2.324509\n",
      "Train Epoch: 0 [37440/60000 (62%)]\tLoss: 2.314780\n",
      "Train Epoch: 0 [37760/60000 (63%)]\tLoss: 2.314119\n",
      "Train Epoch: 0 [38080/60000 (63%)]\tLoss: 2.318530\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 2.297906\n",
      "Train Epoch: 0 [38720/60000 (65%)]\tLoss: 2.316592\n",
      "Train Epoch: 0 [39040/60000 (65%)]\tLoss: 2.341313\n",
      "Train Epoch: 0 [39360/60000 (66%)]\tLoss: 2.280768\n",
      "Train Epoch: 0 [39680/60000 (66%)]\tLoss: 2.279777\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 2.316773\n",
      "Train Epoch: 0 [40320/60000 (67%)]\tLoss: 2.307134\n",
      "Train Epoch: 0 [40640/60000 (68%)]\tLoss: 2.312234\n",
      "Train Epoch: 0 [40960/60000 (68%)]\tLoss: 2.324128\n",
      "Train Epoch: 0 [41280/60000 (69%)]\tLoss: 2.345132\n",
      "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 2.312038\n",
      "Train Epoch: 0 [41920/60000 (70%)]\tLoss: 2.312649\n",
      "Train Epoch: 0 [42240/60000 (70%)]\tLoss: 2.299142\n",
      "Train Epoch: 0 [42560/60000 (71%)]\tLoss: 2.320573\n",
      "Train Epoch: 0 [42880/60000 (71%)]\tLoss: 2.320118\n",
      "Train Epoch: 0 [43200/60000 (72%)]\tLoss: 2.322778\n",
      "Train Epoch: 0 [43520/60000 (73%)]\tLoss: 2.319259\n",
      "Train Epoch: 0 [43840/60000 (73%)]\tLoss: 2.286548\n",
      "Train Epoch: 0 [44160/60000 (74%)]\tLoss: 2.301695\n",
      "Train Epoch: 0 [44480/60000 (74%)]\tLoss: 2.312021\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 2.320906\n",
      "Train Epoch: 0 [45120/60000 (75%)]\tLoss: 2.331185\n",
      "Train Epoch: 0 [45440/60000 (76%)]\tLoss: 2.297367\n",
      "Train Epoch: 0 [45760/60000 (76%)]\tLoss: 2.311667\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 2.291294\n",
      "Train Epoch: 0 [46400/60000 (77%)]\tLoss: 2.344324\n",
      "Train Epoch: 0 [46720/60000 (78%)]\tLoss: 2.309639\n",
      "Train Epoch: 0 [47040/60000 (78%)]\tLoss: 2.263778\n",
      "Train Epoch: 0 [47360/60000 (79%)]\tLoss: 2.336118\n",
      "Train Epoch: 0 [47680/60000 (79%)]\tLoss: 2.311077\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 2.299546\n",
      "Train Epoch: 0 [48320/60000 (81%)]\tLoss: 2.317222\n",
      "Train Epoch: 0 [48640/60000 (81%)]\tLoss: 2.298926\n",
      "Train Epoch: 0 [48960/60000 (82%)]\tLoss: 2.319471\n",
      "Train Epoch: 0 [49280/60000 (82%)]\tLoss: 2.303462\n",
      "Train Epoch: 0 [49600/60000 (83%)]\tLoss: 2.314709\n",
      "Train Epoch: 0 [49920/60000 (83%)]\tLoss: 2.317757\n",
      "Train Epoch: 0 [50240/60000 (84%)]\tLoss: 2.325504\n",
      "Train Epoch: 0 [50560/60000 (84%)]\tLoss: 2.293098\n",
      "Train Epoch: 0 [50880/60000 (85%)]\tLoss: 2.307904\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 2.295748\n",
      "Train Epoch: 0 [51520/60000 (86%)]\tLoss: 2.269739\n",
      "Train Epoch: 0 [51840/60000 (86%)]\tLoss: 2.322697\n",
      "Train Epoch: 0 [52160/60000 (87%)]\tLoss: 2.274448\n",
      "Train Epoch: 0 [52480/60000 (87%)]\tLoss: 2.332935\n",
      "Train Epoch: 0 [52800/60000 (88%)]\tLoss: 2.314940\n",
      "Train Epoch: 0 [53120/60000 (89%)]\tLoss: 2.305191\n",
      "Train Epoch: 0 [53440/60000 (89%)]\tLoss: 2.294666\n",
      "Train Epoch: 0 [53760/60000 (90%)]\tLoss: 2.308648\n",
      "Train Epoch: 0 [54080/60000 (90%)]\tLoss: 2.347615\n",
      "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 2.336278\n",
      "Train Epoch: 0 [54720/60000 (91%)]\tLoss: 2.310206\n",
      "Train Epoch: 0 [55040/60000 (92%)]\tLoss: 2.296442\n",
      "Train Epoch: 0 [55360/60000 (92%)]\tLoss: 2.288143\n",
      "Train Epoch: 0 [55680/60000 (93%)]\tLoss: 2.358331\n",
      "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 2.336667\n",
      "Train Epoch: 0 [56320/60000 (94%)]\tLoss: 2.286435\n",
      "Train Epoch: 0 [56640/60000 (94%)]\tLoss: 2.284611\n",
      "Train Epoch: 0 [56960/60000 (95%)]\tLoss: 2.316246\n",
      "Train Epoch: 0 [57280/60000 (95%)]\tLoss: 2.304166\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 2.294569\n",
      "Train Epoch: 0 [57920/60000 (97%)]\tLoss: 2.316795\n",
      "Train Epoch: 0 [58240/60000 (97%)]\tLoss: 2.305701\n",
      "Train Epoch: 0 [58560/60000 (98%)]\tLoss: 2.323499\n",
      "Train Epoch: 0 [58880/60000 (98%)]\tLoss: 2.282398\n",
      "Train Epoch: 0 [59200/60000 (99%)]\tLoss: 2.310047\n",
      "Train Epoch: 0 [59520/60000 (99%)]\tLoss: 2.288225\n",
      "Train Epoch: 0 [59840/60000 (100%)]\tLoss: 2.330009\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.297459\n",
      "Train Epoch: 1 [320/60000 (1%)]\tLoss: 2.319776\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.333817\n",
      "Train Epoch: 1 [960/60000 (2%)]\tLoss: 2.322258\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.328945\n",
      "Train Epoch: 1 [1600/60000 (3%)]\tLoss: 2.336593\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.328956\n",
      "Train Epoch: 1 [2240/60000 (4%)]\tLoss: 2.330511\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.313447\n",
      "Train Epoch: 1 [2880/60000 (5%)]\tLoss: 2.324724\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.311991\n",
      "Train Epoch: 1 [3520/60000 (6%)]\tLoss: 2.327400\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.294485\n",
      "Train Epoch: 1 [4160/60000 (7%)]\tLoss: 2.302653\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.326293\n",
      "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 2.267704\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.333440\n",
      "Train Epoch: 1 [5440/60000 (9%)]\tLoss: 2.317106\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.327137\n",
      "Train Epoch: 1 [6080/60000 (10%)]\tLoss: 2.309236\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.301806\n",
      "Train Epoch: 1 [6720/60000 (11%)]\tLoss: 2.299857\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.315176\n",
      "Train Epoch: 1 [7360/60000 (12%)]\tLoss: 2.313006\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.289122\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.320167\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.313259\n",
      "Train Epoch: 1 [8640/60000 (14%)]\tLoss: 2.298513\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.302785\n",
      "Train Epoch: 1 [9280/60000 (15%)]\tLoss: 2.294413\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.296843\n",
      "Train Epoch: 1 [9920/60000 (17%)]\tLoss: 2.341637\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.288560\n",
      "Train Epoch: 1 [10560/60000 (18%)]\tLoss: 2.307755\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.345762\n",
      "Train Epoch: 1 [11200/60000 (19%)]\tLoss: 2.295805\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.295425\n",
      "Train Epoch: 1 [11840/60000 (20%)]\tLoss: 2.299164\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.274350\n",
      "Train Epoch: 1 [12480/60000 (21%)]\tLoss: 2.278980\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.304319\n",
      "Train Epoch: 1 [13120/60000 (22%)]\tLoss: 2.271467\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.304466\n",
      "Train Epoch: 1 [13760/60000 (23%)]\tLoss: 2.333722\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.322017\n",
      "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 2.290647\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.308860\n",
      "Train Epoch: 1 [15040/60000 (25%)]\tLoss: 2.299463\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.293232\n",
      "Train Epoch: 1 [15680/60000 (26%)]\tLoss: 2.289545\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.317949\n",
      "Train Epoch: 1 [16320/60000 (27%)]\tLoss: 2.300354\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.337651\n",
      "Train Epoch: 1 [16960/60000 (28%)]\tLoss: 2.299738\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.360097\n",
      "Train Epoch: 1 [17600/60000 (29%)]\tLoss: 2.324300\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.328739\n",
      "Train Epoch: 1 [18240/60000 (30%)]\tLoss: 2.313015\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.297408\n",
      "Train Epoch: 1 [18880/60000 (31%)]\tLoss: 2.307838\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.332721\n",
      "Train Epoch: 1 [19520/60000 (33%)]\tLoss: 2.301753\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.313812\n",
      "Train Epoch: 1 [20160/60000 (34%)]\tLoss: 2.328899\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.299033\n",
      "Train Epoch: 1 [20800/60000 (35%)]\tLoss: 2.355868\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.326190\n",
      "Train Epoch: 1 [21440/60000 (36%)]\tLoss: 2.318294\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.307605\n",
      "Train Epoch: 1 [22080/60000 (37%)]\tLoss: 2.331235\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.314042\n",
      "Train Epoch: 1 [22720/60000 (38%)]\tLoss: 2.330730\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.279864\n",
      "Train Epoch: 1 [23360/60000 (39%)]\tLoss: 2.335214\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.301817\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 2.333576\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.336688\n",
      "Train Epoch: 1 [24640/60000 (41%)]\tLoss: 2.332065\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.341676\n",
      "Train Epoch: 1 [25280/60000 (42%)]\tLoss: 2.312277\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.318107\n",
      "Train Epoch: 1 [25920/60000 (43%)]\tLoss: 2.296076\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.307041\n",
      "Train Epoch: 1 [26560/60000 (44%)]\tLoss: 2.316074\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.323876\n",
      "Train Epoch: 1 [27200/60000 (45%)]\tLoss: 2.349285\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.327081\n",
      "Train Epoch: 1 [27840/60000 (46%)]\tLoss: 2.278307\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.273638\n",
      "Train Epoch: 1 [28480/60000 (47%)]\tLoss: 2.332523\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.314712\n",
      "Train Epoch: 1 [29120/60000 (49%)]\tLoss: 2.299137\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.323979\n",
      "Train Epoch: 1 [29760/60000 (50%)]\tLoss: 2.292325\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.313582\n",
      "Train Epoch: 1 [30400/60000 (51%)]\tLoss: 2.302487\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.301013\n",
      "Train Epoch: 1 [31040/60000 (52%)]\tLoss: 2.342773\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.302007\n",
      "Train Epoch: 1 [31680/60000 (53%)]\tLoss: 2.312576\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.285810\n",
      "Train Epoch: 1 [32320/60000 (54%)]\tLoss: 2.317916\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 2.324790\n",
      "Train Epoch: 1 [32960/60000 (55%)]\tLoss: 2.287084\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 2.338066\n",
      "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 2.298965\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.294285\n",
      "Train Epoch: 1 [34240/60000 (57%)]\tLoss: 2.321706\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.303736\n",
      "Train Epoch: 1 [34880/60000 (58%)]\tLoss: 2.353358\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.360538\n",
      "Train Epoch: 1 [35520/60000 (59%)]\tLoss: 2.333959\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.296156\n",
      "Train Epoch: 1 [36160/60000 (60%)]\tLoss: 2.336342\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 2.344650\n",
      "Train Epoch: 1 [36800/60000 (61%)]\tLoss: 2.361450\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.289834\n",
      "Train Epoch: 1 [37440/60000 (62%)]\tLoss: 2.286884\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 2.309414\n",
      "Train Epoch: 1 [38080/60000 (63%)]\tLoss: 2.326612\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.302371\n",
      "Train Epoch: 1 [38720/60000 (65%)]\tLoss: 2.313636\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 2.315689\n",
      "Train Epoch: 1 [39360/60000 (66%)]\tLoss: 2.288635\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 2.308799\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.299222\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 2.289842\n",
      "Train Epoch: 1 [40640/60000 (68%)]\tLoss: 2.321423\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.315037\n",
      "Train Epoch: 1 [41280/60000 (69%)]\tLoss: 2.308347\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 2.273910\n",
      "Train Epoch: 1 [41920/60000 (70%)]\tLoss: 2.349853\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 2.328489\n",
      "Train Epoch: 1 [42560/60000 (71%)]\tLoss: 2.323707\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 2.301378\n",
      "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 2.293111\n",
      "Train Epoch: 1 [43520/60000 (73%)]\tLoss: 2.311744\n",
      "Train Epoch: 1 [43840/60000 (73%)]\tLoss: 2.296961\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 2.324085\n",
      "Train Epoch: 1 [44480/60000 (74%)]\tLoss: 2.351837\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.332398\n",
      "Train Epoch: 1 [45120/60000 (75%)]\tLoss: 2.316736\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 2.334810\n",
      "Train Epoch: 1 [45760/60000 (76%)]\tLoss: 2.324013\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 2.262429\n",
      "Train Epoch: 1 [46400/60000 (77%)]\tLoss: 2.308712\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 2.337755\n",
      "Train Epoch: 1 [47040/60000 (78%)]\tLoss: 2.296860\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 2.285560\n",
      "Train Epoch: 1 [47680/60000 (79%)]\tLoss: 2.314485\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.276476\n",
      "Train Epoch: 1 [48320/60000 (81%)]\tLoss: 2.340004\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 2.312834\n",
      "Train Epoch: 1 [48960/60000 (82%)]\tLoss: 2.294914\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 2.313577\n",
      "Train Epoch: 1 [49600/60000 (83%)]\tLoss: 2.329784\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 2.330155\n",
      "Train Epoch: 1 [50240/60000 (84%)]\tLoss: 2.318887\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 2.300064\n",
      "Train Epoch: 1 [50880/60000 (85%)]\tLoss: 2.330205\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.309421\n",
      "Train Epoch: 1 [51520/60000 (86%)]\tLoss: 2.330197\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 2.277301\n",
      "Train Epoch: 1 [52160/60000 (87%)]\tLoss: 2.342625\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 2.297565\n",
      "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 2.313268\n",
      "Train Epoch: 1 [53120/60000 (89%)]\tLoss: 2.301597\n",
      "Train Epoch: 1 [53440/60000 (89%)]\tLoss: 2.336612\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 2.299595\n",
      "Train Epoch: 1 [54080/60000 (90%)]\tLoss: 2.308194\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 2.288426\n",
      "Train Epoch: 1 [54720/60000 (91%)]\tLoss: 2.344037\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 2.309049\n",
      "Train Epoch: 1 [55360/60000 (92%)]\tLoss: 2.292379\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 2.315211\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 2.318903\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 2.315310\n",
      "Train Epoch: 1 [56640/60000 (94%)]\tLoss: 2.319596\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 2.314545\n",
      "Train Epoch: 1 [57280/60000 (95%)]\tLoss: 2.331256\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.305278\n",
      "Train Epoch: 1 [57920/60000 (97%)]\tLoss: 2.295403\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 2.281018\n",
      "Train Epoch: 1 [58560/60000 (98%)]\tLoss: 2.285007\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 2.317974\n",
      "Train Epoch: 1 [59200/60000 (99%)]\tLoss: 2.335990\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 2.279808\n",
      "Train Epoch: 1 [59840/60000 (100%)]\tLoss: 2.319798\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.339086\n",
      "Train Epoch: 2 [320/60000 (1%)]\tLoss: 2.296186\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 2.319654\n",
      "Train Epoch: 2 [960/60000 (2%)]\tLoss: 2.326356\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 2.286006\n",
      "Train Epoch: 2 [1600/60000 (3%)]\tLoss: 2.310782\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 2.295420\n",
      "Train Epoch: 2 [2240/60000 (4%)]\tLoss: 2.312461\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 2.293879\n",
      "Train Epoch: 2 [2880/60000 (5%)]\tLoss: 2.299071\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 2.323189\n",
      "Train Epoch: 2 [3520/60000 (6%)]\tLoss: 2.306879\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 2.337970\n",
      "Train Epoch: 2 [4160/60000 (7%)]\tLoss: 2.305448\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 2.346370\n",
      "Train Epoch: 2 [4800/60000 (8%)]\tLoss: 2.296580\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 2.284993\n",
      "Train Epoch: 2 [5440/60000 (9%)]\tLoss: 2.300581\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 2.332244\n",
      "Train Epoch: 2 [6080/60000 (10%)]\tLoss: 2.341417\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 2.304019\n",
      "Train Epoch: 2 [6720/60000 (11%)]\tLoss: 2.336119\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 2.303675\n",
      "Train Epoch: 2 [7360/60000 (12%)]\tLoss: 2.298055\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 2.295628\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 2.334542\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 2.277242\n",
      "Train Epoch: 2 [8640/60000 (14%)]\tLoss: 2.345845\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 2.302561\n",
      "Train Epoch: 2 [9280/60000 (15%)]\tLoss: 2.311997\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 2.310092\n",
      "Train Epoch: 2 [9920/60000 (17%)]\tLoss: 2.325539\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 2.301694\n",
      "Train Epoch: 2 [10560/60000 (18%)]\tLoss: 2.304468\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 2.341217\n",
      "Train Epoch: 2 [11200/60000 (19%)]\tLoss: 2.327139\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 2.324158\n",
      "Train Epoch: 2 [11840/60000 (20%)]\tLoss: 2.314315\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 2.308420\n",
      "Train Epoch: 2 [12480/60000 (21%)]\tLoss: 2.314210\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.284304\n",
      "Train Epoch: 2 [13120/60000 (22%)]\tLoss: 2.309318\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 2.294528\n",
      "Train Epoch: 2 [13760/60000 (23%)]\tLoss: 2.292487\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 2.295307\n",
      "Train Epoch: 2 [14400/60000 (24%)]\tLoss: 2.323925\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 2.290480\n",
      "Train Epoch: 2 [15040/60000 (25%)]\tLoss: 2.323137\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 2.307019\n",
      "Train Epoch: 2 [15680/60000 (26%)]\tLoss: 2.309669\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.312646\n",
      "Train Epoch: 2 [16320/60000 (27%)]\tLoss: 2.300946\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 2.297564\n",
      "Train Epoch: 2 [16960/60000 (28%)]\tLoss: 2.320853\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 2.338560\n",
      "Train Epoch: 2 [17600/60000 (29%)]\tLoss: 2.292158\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 2.307822\n",
      "Train Epoch: 2 [18240/60000 (30%)]\tLoss: 2.325511\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 2.349514\n",
      "Train Epoch: 2 [18880/60000 (31%)]\tLoss: 2.315769\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 2.339496\n",
      "Train Epoch: 2 [19520/60000 (33%)]\tLoss: 2.284451\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 2.313180\n",
      "Train Epoch: 2 [20160/60000 (34%)]\tLoss: 2.321968\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 2.298344\n",
      "Train Epoch: 2 [20800/60000 (35%)]\tLoss: 2.299283\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 2.289478\n",
      "Train Epoch: 2 [21440/60000 (36%)]\tLoss: 2.321712\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 2.301308\n",
      "Train Epoch: 2 [22080/60000 (37%)]\tLoss: 2.292173\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 2.323859\n",
      "Train Epoch: 2 [22720/60000 (38%)]\tLoss: 2.305005\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 2.328659\n",
      "Train Epoch: 2 [23360/60000 (39%)]\tLoss: 2.321348\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 2.298184\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 2.309580\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 2.318334\n",
      "Train Epoch: 2 [24640/60000 (41%)]\tLoss: 2.298089\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 2.294227\n",
      "Train Epoch: 2 [25280/60000 (42%)]\tLoss: 2.312283\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.320085\n",
      "Train Epoch: 2 [25920/60000 (43%)]\tLoss: 2.292881\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 2.308954\n",
      "Train Epoch: 2 [26560/60000 (44%)]\tLoss: 2.348568\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 2.299100\n",
      "Train Epoch: 2 [27200/60000 (45%)]\tLoss: 2.255910\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 2.365253\n",
      "Train Epoch: 2 [27840/60000 (46%)]\tLoss: 2.305087\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 2.323956\n",
      "Train Epoch: 2 [28480/60000 (47%)]\tLoss: 2.317557\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 2.283313\n",
      "Train Epoch: 2 [29120/60000 (49%)]\tLoss: 2.316828\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 2.317213\n",
      "Train Epoch: 2 [29760/60000 (50%)]\tLoss: 2.313056\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 2.304344\n",
      "Train Epoch: 2 [30400/60000 (51%)]\tLoss: 2.349982\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 2.286753\n",
      "Train Epoch: 2 [31040/60000 (52%)]\tLoss: 2.306595\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 2.270065\n",
      "Train Epoch: 2 [31680/60000 (53%)]\tLoss: 2.335327\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.309969\n",
      "Train Epoch: 2 [32320/60000 (54%)]\tLoss: 2.299775\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 2.315107\n",
      "Train Epoch: 2 [32960/60000 (55%)]\tLoss: 2.311044\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 2.309644\n",
      "Train Epoch: 2 [33600/60000 (56%)]\tLoss: 2.331163\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 2.283795\n",
      "Train Epoch: 2 [34240/60000 (57%)]\tLoss: 2.306190\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 2.280782\n",
      "Train Epoch: 2 [34880/60000 (58%)]\tLoss: 2.330718\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 2.312153\n",
      "Train Epoch: 2 [35520/60000 (59%)]\tLoss: 2.306707\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 2.331929\n",
      "Train Epoch: 2 [36160/60000 (60%)]\tLoss: 2.311494\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 2.332794\n",
      "Train Epoch: 2 [36800/60000 (61%)]\tLoss: 2.330741\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 2.267760\n",
      "Train Epoch: 2 [37440/60000 (62%)]\tLoss: 2.335913\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 2.296440\n",
      "Train Epoch: 2 [38080/60000 (63%)]\tLoss: 2.282366\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.335562\n",
      "Train Epoch: 2 [38720/60000 (65%)]\tLoss: 2.320647\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 2.323213\n",
      "Train Epoch: 2 [39360/60000 (66%)]\tLoss: 2.302224\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 2.306082\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.309906\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 2.331387\n",
      "Train Epoch: 2 [40640/60000 (68%)]\tLoss: 2.312245\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 2.320803\n",
      "Train Epoch: 2 [41280/60000 (69%)]\tLoss: 2.333467\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 2.307334\n",
      "Train Epoch: 2 [41920/60000 (70%)]\tLoss: 2.296343\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 2.336697\n",
      "Train Epoch: 2 [42560/60000 (71%)]\tLoss: 2.328551\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 2.317767\n",
      "Train Epoch: 2 [43200/60000 (72%)]\tLoss: 2.335175\n",
      "Train Epoch: 2 [43520/60000 (73%)]\tLoss: 2.298210\n",
      "Train Epoch: 2 [43840/60000 (73%)]\tLoss: 2.320480\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 2.338857\n",
      "Train Epoch: 2 [44480/60000 (74%)]\tLoss: 2.289492\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 2.304486\n",
      "Train Epoch: 2 [45120/60000 (75%)]\tLoss: 2.289739\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 2.299696\n",
      "Train Epoch: 2 [45760/60000 (76%)]\tLoss: 2.321643\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 2.322966\n",
      "Train Epoch: 2 [46400/60000 (77%)]\tLoss: 2.317166\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 2.328883\n",
      "Train Epoch: 2 [47040/60000 (78%)]\tLoss: 2.299332\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 2.306957\n",
      "Train Epoch: 2 [47680/60000 (79%)]\tLoss: 2.330810\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 2.310949\n",
      "Train Epoch: 2 [48320/60000 (81%)]\tLoss: 2.299711\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 2.298593\n",
      "Train Epoch: 2 [48960/60000 (82%)]\tLoss: 2.304005\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 2.303326\n",
      "Train Epoch: 2 [49600/60000 (83%)]\tLoss: 2.311670\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 2.316855\n",
      "Train Epoch: 2 [50240/60000 (84%)]\tLoss: 2.316194\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 2.289169\n",
      "Train Epoch: 2 [50880/60000 (85%)]\tLoss: 2.335315\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.306508\n",
      "Train Epoch: 2 [51520/60000 (86%)]\tLoss: 2.313368\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 2.324852\n",
      "Train Epoch: 2 [52160/60000 (87%)]\tLoss: 2.299369\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 2.329009\n",
      "Train Epoch: 2 [52800/60000 (88%)]\tLoss: 2.313300\n",
      "Train Epoch: 2 [53120/60000 (89%)]\tLoss: 2.328881\n",
      "Train Epoch: 2 [53440/60000 (89%)]\tLoss: 2.278026\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 2.314600\n",
      "Train Epoch: 2 [54080/60000 (90%)]\tLoss: 2.319677\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 2.335886\n",
      "Train Epoch: 2 [54720/60000 (91%)]\tLoss: 2.329382\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 2.315713\n",
      "Train Epoch: 2 [55360/60000 (92%)]\tLoss: 2.317037\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 2.315770\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 2.311320\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 2.312119\n",
      "Train Epoch: 2 [56640/60000 (94%)]\tLoss: 2.312253\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 2.297695\n",
      "Train Epoch: 2 [57280/60000 (95%)]\tLoss: 2.300185\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 2.309261\n",
      "Train Epoch: 2 [57920/60000 (97%)]\tLoss: 2.333846\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 2.296827\n",
      "Train Epoch: 2 [58560/60000 (98%)]\tLoss: 2.319169\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 2.334146\n",
      "Train Epoch: 2 [59200/60000 (99%)]\tLoss: 2.302853\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 2.307481\n",
      "Train Epoch: 2 [59840/60000 (100%)]\tLoss: 2.320597\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.304642\n",
      "Train Epoch: 3 [320/60000 (1%)]\tLoss: 2.291959\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 2.309057\n",
      "Train Epoch: 3 [960/60000 (2%)]\tLoss: 2.321104\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 2.340433\n",
      "Train Epoch: 3 [1600/60000 (3%)]\tLoss: 2.362581\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 2.260054\n",
      "Train Epoch: 3 [2240/60000 (4%)]\tLoss: 2.316822\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 2.323383\n",
      "Train Epoch: 3 [2880/60000 (5%)]\tLoss: 2.290923\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 2.322838\n",
      "Train Epoch: 3 [3520/60000 (6%)]\tLoss: 2.324908\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 2.350849\n",
      "Train Epoch: 3 [4160/60000 (7%)]\tLoss: 2.289222\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 2.315062\n",
      "Train Epoch: 3 [4800/60000 (8%)]\tLoss: 2.315405\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 2.318313\n",
      "Train Epoch: 3 [5440/60000 (9%)]\tLoss: 2.302543\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 2.303837\n",
      "Train Epoch: 3 [6080/60000 (10%)]\tLoss: 2.298008\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 2.299561\n",
      "Train Epoch: 3 [6720/60000 (11%)]\tLoss: 2.328071\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 2.286791\n",
      "Train Epoch: 3 [7360/60000 (12%)]\tLoss: 2.297414\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 2.271777\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 2.342120\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 2.314504\n",
      "Train Epoch: 3 [8640/60000 (14%)]\tLoss: 2.304371\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 2.293603\n",
      "Train Epoch: 3 [9280/60000 (15%)]\tLoss: 2.286603\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 2.326101\n",
      "Train Epoch: 3 [9920/60000 (17%)]\tLoss: 2.270663\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 2.299592\n",
      "Train Epoch: 3 [10560/60000 (18%)]\tLoss: 2.288953\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 2.309439\n",
      "Train Epoch: 3 [11200/60000 (19%)]\tLoss: 2.336755\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 2.303726\n",
      "Train Epoch: 3 [11840/60000 (20%)]\tLoss: 2.291635\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 2.317266\n",
      "Train Epoch: 3 [12480/60000 (21%)]\tLoss: 2.293148\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.321480\n",
      "Train Epoch: 3 [13120/60000 (22%)]\tLoss: 2.298429\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 2.328587\n",
      "Train Epoch: 3 [13760/60000 (23%)]\tLoss: 2.334032\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 2.301528\n",
      "Train Epoch: 3 [14400/60000 (24%)]\tLoss: 2.326733\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 2.313235\n",
      "Train Epoch: 3 [15040/60000 (25%)]\tLoss: 2.349932\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 2.305990\n",
      "Train Epoch: 3 [15680/60000 (26%)]\tLoss: 2.342796\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 2.311463\n",
      "Train Epoch: 3 [16320/60000 (27%)]\tLoss: 2.263875\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 2.290734\n",
      "Train Epoch: 3 [16960/60000 (28%)]\tLoss: 2.290088\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 2.328818\n",
      "Train Epoch: 3 [17600/60000 (29%)]\tLoss: 2.311948\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 2.323168\n",
      "Train Epoch: 3 [18240/60000 (30%)]\tLoss: 2.300582\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 2.306364\n",
      "Train Epoch: 3 [18880/60000 (31%)]\tLoss: 2.317309\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 2.300094\n",
      "Train Epoch: 3 [19520/60000 (33%)]\tLoss: 2.284420\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 2.317804\n",
      "Train Epoch: 3 [20160/60000 (34%)]\tLoss: 2.310844\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 2.318991\n",
      "Train Epoch: 3 [20800/60000 (35%)]\tLoss: 2.309300\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 2.292265\n",
      "Train Epoch: 3 [21440/60000 (36%)]\tLoss: 2.292910\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 2.308456\n",
      "Train Epoch: 3 [22080/60000 (37%)]\tLoss: 2.304023\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 2.314952\n",
      "Train Epoch: 3 [22720/60000 (38%)]\tLoss: 2.322671\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 2.297287\n",
      "Train Epoch: 3 [23360/60000 (39%)]\tLoss: 2.289289\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 2.341873\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 2.348441\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 2.300580\n",
      "Train Epoch: 3 [24640/60000 (41%)]\tLoss: 2.323275\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 2.340551\n",
      "Train Epoch: 3 [25280/60000 (42%)]\tLoss: 2.299536\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.302310\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m parser \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mArgumentParser()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test(model, device, test_loader)\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epochs, log_interval)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/masterstage/.conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/masterstage/.conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/masterstage/.conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/masterstage/.conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/masterstage/.conda/lib/python3.11/site-packages/torchvision/datasets/mnist.py:138\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "train(model, device, train_loader, optimizer)\n",
    "test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
