{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple fully connected model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(filename='pipeline.log', encoding='utf-8', level=logging.DEBUG, filemode='w')\n",
    "\n",
    "logger.info('Defining models')\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "            )\n",
    "        self.start_layer = 0\n",
    "        self.end_layer = len(self.model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.squeeze(x)\n",
    "        if self.start_layer == 0:\n",
    "            x = x.view(-1, 28*28)\n",
    "        for i in range(self.start_layer, self.end_layer):\n",
    "            x = self.model[i](x)\n",
    "        if self.end_layer == len(self.model):\n",
    "            x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def set_start_layer(self, i):\n",
    "        self.start_layer = i\n",
    "\n",
    "    def set_end_layer(self, i):\n",
    "        self.end_layer = i\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1,32,(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Conv2d(32, 64, (3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1600, 10)\n",
    "        )\n",
    "        self.start_layer = 0\n",
    "        self.end_layer = len(self.model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.start_layer, self.end_layer):\n",
    "            x = self.model[i](x)\n",
    "        if self.end_layer == len(self.model):\n",
    "            x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def set_start_layer(self, i):\n",
    "        self.start_layer = i\n",
    "\n",
    "    def set_end_layer(self, i):\n",
    "        self.end_layer = i\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "logger.info('Initializing settings')\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "                    help='number of epochs to train (default: 14)')\n",
    "parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "                    help='learning rate (default: 1.0)')\n",
    "parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                    help='Learning rate step gamma (default: 0.7)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--no-mps', action='store_true', default=False,\n",
    "                    help='disables macOS GPU training')\n",
    "parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                    help='quickly check a single pass')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save-model', action='store_true', default=True,\n",
    "                    help='For Saving the current Model')\n",
    "args, unknown = parser.parse_known_args()\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "elif use_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "test_kwargs = {'batch_size': args.test_batch_size}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                    'pin_memory': True,\n",
    "                    'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                    transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "def train_model(modeltype: str):\n",
    "    logger.info(f'Training {modeltype} model')\n",
    "    match modeltype:\n",
    "        case 'cnn':\n",
    "            model = ConvNet().to(device)\n",
    "        case 'fc':\n",
    "            model = Net().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in tqdm(range(1, args.epochs + 1)):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), f\"mnist_{modeltype}.pt\")\n",
    "\n",
    "def load_model(filename: str, type: str='cnn', test: bool=False):\n",
    "    \"\"\" \n",
    "    load the model from the .pt file and evaluate on the test set if requested\n",
    "    :param filename: str of model save filename\n",
    "    :param test: bool dictating if the model is tested\n",
    "    :return: loaded model\n",
    "    \"\"\"\n",
    "    logger.info(f'Loading model from file {filename}')\n",
    "    modeldict = torch.load(filename)\n",
    "    if type == 'cnn':\n",
    "        model = ConvNet()\n",
    "    else:\n",
    "        model = Net()\n",
    "    model.load_state_dict(modeldict)\n",
    "    if test:\n",
    "        test(model, device, test_loader)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model for investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, _ = next(iter(test_loader))\n",
    "model = load_model('mnist_cnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waarde van 'pixel' fluctueren van 0 naar 1 en kijken wat het effect is op de output van het model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mogelijke richtingen: r as, r random, r gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient: ipv loss.backward kan je y.backward of je hebt w.grad en x.grad (misschien met x.requiresGradient=True). \\\\\n",
    "\n",
    "Torch sequential: hooks/forward hook. layer.addForwardHook(x,... lambda x: )\\\\\n",
    "\n",
    "Ook backward hook voor de gradient. \n",
    "\n",
    "Importance estimation with imprinting:\n",
    "https://openaccess.thecvf.com/content/CVPR2021W/MAI/papers/Liu_Layer_Importance_Estimation_With_Imprinting_for_Neural_Network_Quantization_CVPRW_2021_paper.pdf \n",
    "\n",
    "Importance estimation with pruning:\n",
    "https://openaccess.thecvf.com/content_CVPR_2019/papers/Molchanov_Importance_Estimation_for_Neural_Network_Pruning_CVPR_2019_paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x+ar) = f(x) + arf'(x)\n",
    "\n",
    "f(x) - output shape\n",
    "f'(x) - input*output shape\n",
    "r : input shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the modulated input through the model and save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def random_axis(tensor: torch.Tensor): \n",
    "    \"\"\"\n",
    "    set a random value in an input-shaped tensor of zeros to 1, dictating a random direction along the axis to take the steps in\n",
    "    :param tensor: input-shaped tensor of zeros\n",
    "    :return: tensor of zeros and a 1\n",
    "    \"\"\"\n",
    "    input_length = len(tensor.flatten())\n",
    "\n",
    "    random_numbers = np.array(random.sample(range(0, input_length), input_length))\n",
    "    random_numbers = random_numbers.reshape(np.array(tensor).shape)\n",
    "\n",
    "    random_index = random.sample(range(0, input_length), 1)\n",
    "    random_index = np.where(random_numbers == random_index)\n",
    "    \n",
    "    tensor[random_index] = 1\n",
    "    return tensor\n",
    "\n",
    "def forward_runs(startinput: torch.Tensor, model, layergroups: list, dirtype: str=None, steps: list=np.logspace(-5,1,6)):\n",
    "    \"\"\"\n",
    "    run through the model while creating inputs at the different steps with the given direction. save the outputs for further inspection\n",
    "    :param input: tensor input to the first layer\n",
    "    :param model: neural network \n",
    "    :param dirtype: string describing the method used to find a direction\n",
    "    :return: inputs into each layer with step adjustments, corresponding outputs, dirs, steps and grads\n",
    "    \"\"\"\n",
    "    startinput.requires_grad = True\n",
    "    logger.info(f'Starting forward runs with groups {layergroups} and steps {steps}')\n",
    "\n",
    "    #for dicts:\n",
    "    dictgroups = []\n",
    "    dictsteps = []\n",
    "    dictinputs = []\n",
    "    dictoutputs = []\n",
    "    dictdirs = []\n",
    "    dictgrads = []\n",
    "\n",
    "    for group in layergroups:\n",
    "        print(group)\n",
    "        logger.info(f'{group}')\n",
    "        input = startinput\n",
    "        firstlayer = model.model[group[0]]\n",
    "\n",
    "        firstlayer_idx = np.where(np.isin(model.model, firstlayer))[0][0]\n",
    "        if firstlayer_idx > 0:\n",
    "            model.set_start_layer(0)\n",
    "            model.set_end_layer(firstlayer_idx)\n",
    "            input = model(input)\n",
    "        elif type(model) != ConvNet:\n",
    "            input = input.flatten()\n",
    "\n",
    "        print('here')\n",
    "\n",
    "        \n",
    "        model.set_start_layer(group[0])\n",
    "        model.set_end_layer(group[-1])\n",
    "\n",
    "        grad = torch.autograd.functional.jacobian(model, input)\n",
    "        print('here')\n",
    "        dir = direction(dirtype, input, grad, modeltype=type(model))\n",
    "\n",
    "        print(startinput.shape, input.shape, grad.shape, dir.shape)\n",
    "        dictgroups.append(str(group))\n",
    "        dictsteps.append(0.)\n",
    "        dictinputs.append(input.detach().clone())\n",
    "        dictoutputs.append(model(input).detach().clone())\n",
    "        dictdirs.append(dir)\n",
    "        dictgrads.append(grad)\n",
    "\n",
    "        for step in steps:\n",
    "            logger.info(f'{step}')\n",
    "            # print(input.shape, dir.shape)\n",
    "            newinput = input.detach() + step*dir\n",
    "            newoutput = model(newinput)\n",
    "            # print(newoutput.shape, grad.shape, dir.shape)\n",
    "            inp = newinput.detach().clone()\n",
    "            outp = newoutput.detach().clone()\n",
    "\n",
    "            dictgrad = torch.autograd.functional.jacobian(model, input)\n",
    "            logger.info(f'{inp.shape, outp.shape, dir.shape, dictgrad.shape}')\n",
    "            dictgroups.append(str(group))\n",
    "            dictsteps.append(step)\n",
    "            dictinputs.append(inp)\n",
    "            dictoutputs.append(outp)\n",
    "            dictdirs.append(dir)\n",
    "            dictgrads.append(dictgrad)\n",
    "\n",
    "    dic = {'group': dictgroups, 'step': dictsteps, 'input': dictinputs, 'output': dictoutputs, 'grad': dictgrads, 'dir': dictdirs}\n",
    "    df = pd.DataFrame.from_dict(dic)\n",
    "    model.set_start_layer(0)\n",
    "    model.set_end_layer(len(model.model))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('mnist_fc.pt', 'fc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction(method: str, input: torch.Tensor, grad: torch.Tensor=None, modeltype=Net):\n",
    "    \"\"\"\n",
    "    calculate the direction of a step given the requested direction type and the input\n",
    "    :param method: string defining the method for calculating the direction ('axis', 'random' or 'gradient')\n",
    "    :param input: input to the layer to be investigated\n",
    "    :return: tensor array with the same shape as the input describing the direction\n",
    "    \"\"\"\n",
    "    dir = torch.ones_like(input)\n",
    "    match method:\n",
    "        case 'axis':\n",
    "            dir = torch.zeros_like(dir)\n",
    "            dir = random_axis(dir)\n",
    "        case 'random':\n",
    "            dir = torch.rand_like(dir) #normal\n",
    "        case 'gradient':\n",
    "            if modeltype == ConvNet:\n",
    "                # print(grad.shape)\n",
    "                ones = np.ones(grad.T.shape[3:])\n",
    "                grad = grad.T.flatten(start_dim=3)\n",
    "                # print(grad.shape, ones.shape)\n",
    "                dir = np.dot(grad, ones.flatten()).T\n",
    "            elif modeltype == Net:\n",
    "                grad = grad.squeeze()\n",
    "                dir = grad.T@torch.ones(grad.shape[0])\n",
    "        case _:\n",
    "            warnings.warn('Unknown direction type, using all directions', RuntimeWarning)\n",
    "            pass\n",
    "    if type(dir) != torch.Tensor:\n",
    "        dir = torch.tensor(dir)\n",
    "    # print(dir.shape)\n",
    "    return dir/torch.sum(dir) #normalisatie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_exp_act(df: pd.DataFrame, conv: bool=False):\n",
    "    \"\"\" \n",
    "    calculate the expected outputs assuming linearity, and take the actual outputs from the model\n",
    "    :param df: \n",
    "    :return: expected outputs assuming linearity and actual outputs\n",
    "    \"\"\"\n",
    "    logger.info('Calculating non-linearities')\n",
    "    dictgroups = []\n",
    "    dictsteps = []\n",
    "    dictlins = []\n",
    "    for group in np.unique(df['group']):\n",
    "        for step in np.unique(df['step']):\n",
    "            print(group, step)\n",
    "            logger.info(f'{group} {step}')\n",
    "            dfoi = df[(df['group']==str(group)) & (df['step']==step)]\n",
    "\n",
    "            step = list(dfoi['step'])[0]\n",
    "            act = list(dfoi['output'])[0]\n",
    "            grad = list(dfoi['grad'])[0]\n",
    "            dir = list(dfoi['dir'])[0]\n",
    "\n",
    "            nostep = list(df[(df['group'] == str(group)) & (df['step'] == 0.)]['output'])[0]\n",
    "            if conv:\n",
    "                grad = grad.flatten(start_dim=len(grad.shape)-3)\n",
    "                dir = dir.flatten()\n",
    "            print(nostep.shape, grad.shape, dir.shape)\n",
    "            exp = nostep + step*np.matmul(grad, dir)\n",
    "            diff = exp - act\n",
    "            lin = np.linalg.norm(diff)/step\n",
    "            logger.info(f'{grad.shape}, {dir.shape}, {nostep.shape}, {exp.shape}')\n",
    "\n",
    "            dictgroups.append(group)\n",
    "            dictsteps.append(step)\n",
    "            dictlins.append(lin)\n",
    "\n",
    "    dic = {'group': dictgroups, 'step': dictsteps, 'lin': dictlins}\n",
    "    df = pd.DataFrame.from_dict(dic)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "richting meenemen tussen lagen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input shape: [1,28,28]\n",
    "output shape: [32, 26, 26]\n",
    "grad shape: [32, 26, 26, 1, 28, 28]\n",
    "expected dir shape: [1, 28, 28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x+ar) = f(x) + arf'(x)\n",
    "\n",
    "En checken of dit binnen threshold blijft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x+ar)=f(x) +arf'(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(model_type, df: pd.DataFrame, dir: str, ylog: bool):\n",
    "    \"\"\" \n",
    "    plot the L2 norms per step size for each layer in the model\n",
    "    :param model: model to be investigated\n",
    "    :param lindf: \n",
    "    :param dir: str describing step direction\n",
    "    \"\"\"\n",
    "    logger.info(f'plotting for model {model_type} and dir {dir}')\n",
    "    zero = np.zeros(len(df['step'].unique()))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1, layout='constrained', figsize=(7,4))\n",
    "    groups = np.unique(df['group'])\n",
    "    for i, group in enumerate(groups):\n",
    "        dfoi = df[df['group'] == group]\n",
    "        axs.plot(dfoi['step'], dfoi['lin'], label=f'{group}', alpha=0.7)\n",
    "    # for ax in axs:\n",
    "        \n",
    "    axs.plot(dfoi['step'], zero, label='zero-line')\n",
    "    \n",
    "    axs.set_xscale('log')\n",
    "    if ylog:\n",
    "        axs.set_yscale('log')\n",
    "    axs.legend()\n",
    "    axs.set_ylabel('$L_{2,2}$ norm')\n",
    "    axs.set_xlabel('Step size')\n",
    "    fig.suptitle(f\"Non-linearity per step size in direction '{dir}'\")\n",
    "    plt.savefig(f'./plots/{model_type}_{dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(model_type: str, dir: str, groups: list, steps: list, repeats: int=3, test_loader=test_loader):\n",
    "    \"\"\"\n",
    "    calculate linearity per layer given a model and test loader, and plot the results\n",
    "    :param model_name: string of model save filename\n",
    "    :param test_loader: test data loader\n",
    "    \"\"\"\n",
    "    logger.info(f'Starting pipeline for model {model_type} with dir {dir}')\n",
    "    if model_type == 'cnn':\n",
    "        model = load_model('mnist_cnn.pt', 'cnn')\n",
    "        conv = True\n",
    "    elif model_type == 'fc':\n",
    "        model = load_model('mnist_fc.pt', 'fc')\n",
    "        conv = False\n",
    "    else:\n",
    "        raise RuntimeError('Unrecognized model type')\n",
    "    fulldf = pd.DataFrame()\n",
    "    for i in range(repeats):\n",
    "        input = next(iter(test_loader))[0]\n",
    "        df = forward_runs(input[0], model, groups, dir, steps)\n",
    "        lindf = calc_exp_act(df, conv)\n",
    "        fulldf = pd.concat([lindf, fulldf], axis=0)\n",
    "    return fulldf\n",
    "    plot(model_type, lindf, dir, True)\n",
    "    return lindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    logger.info(f'Starting runs')\n",
    "    groups = [[0,3],[0,4],[1,3],[1,4],[2,4]]\n",
    "    steps = np.logspace(-5,1,6)\n",
    "    pipeline('fc', 'gradient', groups, steps)\n",
    "    pipeline('fc', 'axis', groups, steps)\n",
    "    pipeline('fc', 'random', groups, steps)\n",
    "    return\n",
    "    groups = [[0,3], [3,6],[6,8]]\n",
    "    df = pipeline('cnn', 'gradient', groups, steps)\n",
    "    pipeline('cnn', 'axis', groups, steps)\n",
    "    pipeline('cnn', 'random', groups, steps)\n",
    "\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([784]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([784]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[1, 3]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[0, 3] 0.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 1e-05\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.00015848931924611142\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.0025118864315095794\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.03981071705534969\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.630957344480193\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 10.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 1e-05\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.00015848931924611142\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.0025118864315095794\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.03981071705534969\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.630957344480193\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 10.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[1, 3] 0.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 1e-05\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.00015848931924611142\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.0025118864315095794\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.03981071705534969\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.630957344480193\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 10.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 1e-05\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.00015848931924611142\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.0025118864315095794\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.03981071705534969\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.630957344480193\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40990/287106826.py:29: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  lin = np.linalg.norm(diff)/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4] 10.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 1e-05\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.00015848931924611142\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.0025118864315095794\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.03981071705534969\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.630957344480193\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 10.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[0, 3]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([784]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([784]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[1, 3]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[0, 3] 0.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 1e-05\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.00015848931924611142\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.0025118864315095794\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.03981071705534969\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.630957344480193\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 10.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 1e-05\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.00015848931924611142\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.0025118864315095794\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.03981071705534969\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.630957344480193\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 10.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[1, 3] 0.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 1e-05\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.00015848931924611142\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.0025118864315095794\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.03981071705534969\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.630957344480193\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 10.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 1e-05\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.00015848931924611142\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.0025118864315095794\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.03981071705534969\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.630957344480193\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 10.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 1e-05\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.00015848931924611142\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.0025118864315095794\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.03981071705534969\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.630957344480193\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 10.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[0, 3]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([784]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([784]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[1, 3]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[0, 3] 0.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 1e-05\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.00015848931924611142\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.0025118864315095794\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.03981071705534969\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.630957344480193\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 10.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 1e-05\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.00015848931924611142\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.0025118864315095794\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.03981071705534969\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.630957344480193\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 10.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[1, 3] 0.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 1e-05\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.00015848931924611142\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.0025118864315095794\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.03981071705534969\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 0.630957344480193\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 3] 10.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 1e-05\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.00015848931924611142\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.0025118864315095794\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.03981071705534969\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 0.630957344480193\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[1, 4] 10.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 1e-05\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.00015848931924611142\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.0025118864315095794\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.03981071705534969\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 0.630957344480193\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[2, 4] 10.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([512])\n",
      "[0, 3]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([784]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([784]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[1, 3]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([1, 512])\n",
      "[1, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([1, 512])\n",
      "[2, 4]\n",
      "here\n",
      "here\n",
      "torch.Size([1, 28, 28]) torch.Size([1, 512]) torch.Size([512, 1, 512]) torch.Size([1, 512])\n",
      "[0, 3] 0.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 1e-05\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.00015848931924611142\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.0025118864315095794\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.03981071705534969\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 0.630957344480193\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 3] 10.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 1e-05\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.00015848931924611142\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.0025118864315095794\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.03981071705534969\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 0.630957344480193\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[0, 4] 10.0\n",
      "torch.Size([1, 512]) torch.Size([1, 512, 784]) torch.Size([784])\n",
      "[1, 3] 0.0\n",
      "torch.Size([512]) torch.Size([512, 1, 512]) torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40990/287106826.py:29: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  lin = np.linalg.norm(diff)/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m steps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m      5\u001b[0m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradient\u001b[39m\u001b[38;5;124m'\u001b[39m, groups, steps)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maxis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m, groups, steps)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(model_type, dir, groups, steps, repeats, test_loader)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(test_loader))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m     df \u001b[38;5;241m=\u001b[39m forward_runs(\u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m0\u001b[39m], model, groups, \u001b[38;5;28mdir\u001b[39m, steps)\n\u001b[0;32m---> 20\u001b[0m     lindf \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_exp_act\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     fulldf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([lindf, fulldf], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fulldf\n",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m, in \u001b[0;36mcalc_exp_act\u001b[0;34m(df, conv)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(nostep\u001b[38;5;241m.\u001b[39mshape, grad\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 27\u001b[0m exp \u001b[38;5;241m=\u001b[39m nostep \u001b[38;5;241m+\u001b[39m step\u001b[38;5;241m*\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m diff \u001b[38;5;241m=\u001b[39m exp \u001b[38;5;241m-\u001b[39m act\n\u001b[1;32m     29\u001b[0m lin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(diff)\u001b[38;5;241m/\u001b[39mstep\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 512)"
     ]
    }
   ],
   "source": [
    "df = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions:\\\n",
    "Conv(32,3,3) + maxpool:\\\n",
    "1x28x28 -> 32x13x13 \n",
    "\n",
    "f(x+ar) = f(x) + arf'(x)\n",
    "\n",
    "f'(x): 32x13x13x1x28x28\\\n",
    "r: 1x28x28 -> flatten?\n",
    "\n",
    "32x13x13x1x28x28 x 1x28x28\n",
    "\n",
    "Direction meenemen bij verschillende groepen? Dimensie verandert\n",
    "\n",
    "||f(x+ar) - (f(x) + arf'(x))||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch normalize met dim=alle dims (tenzij bij batches)\\\n",
    "ReLU(x+d*w) -> x+d moet groter dan nul worden om de non-lineariteit te krijgen\\\n",
    "Dus d kan berekend worden waar de ReLU omdraait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>step</th>\n",
       "      <th>lin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.003220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.032193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0, 6]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0, 6]</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 6]</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0, 6]</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.002516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0, 6]</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.025161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0, 6]</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.250878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.001602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.016019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     group     step       lin\n",
       "0   [0, 3]  0.00000  0.000000\n",
       "1   [0, 3]  0.00001  0.000003\n",
       "2   [0, 3]  0.00010  0.000032\n",
       "3   [0, 3]  0.00100  0.000322\n",
       "4   [0, 3]  0.01000  0.003220\n",
       "5   [0, 3]  0.10000  0.032193\n",
       "6   [0, 6]  0.00000  0.000000\n",
       "7   [0, 6]  0.00001  0.000025\n",
       "8   [0, 6]  0.00010  0.000252\n",
       "9   [0, 6]  0.00100  0.002516\n",
       "10  [0, 6]  0.01000  0.025161\n",
       "11  [0, 6]  0.10000  0.250878\n",
       "12  [3, 6]  0.00000  0.000000\n",
       "13  [3, 6]  0.00001  0.000002\n",
       "14  [3, 6]  0.00010  0.000016\n",
       "15  [3, 6]  0.00100  0.000160\n",
       "16  [3, 6]  0.01000  0.001602\n",
       "17  [3, 6]  0.10000  0.016019"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checken of we andere resultaten hebben met doubles.\\\n",
    "waarom geen 0 bij kleine stappen? \\\n",
    "checken wat gradient van ReLU is bij x=0\n",
    "bij linear layers verwachten we lineariteit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wat als we een groep lagen lineair benadert?\\\n",
    "kan je een groep lagen vervangen door een lineaire laag met gewichten berekend adhv de gradient van de lagen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_output_hook(self, module, input, output):\n",
    "    self.input = input\n",
    "    self.output = output\n",
    "\n",
    "def gradient_hook(self, module, input: torch.tensor, output: torch.tensor):\n",
    "    output.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
